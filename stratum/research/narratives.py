"""Attack scenario narratives for findings.

Each finding gets a concrete attack narrative templated with project-specific
details (crew names, tool names, file paths). The developer reads a story
about THEIR code, not a generic best practice.
"""
from __future__ import annotations


# Maps finding IDs to their relevant breach patterns (v4).
# Only show a breach match when the finding actually matches the pattern.
FINDING_BREACH_MAP: dict[str, list[str]] = {
    "STRATUM-001": ["ECHOLEAK-2025", "SLACK-AI-EXFIL-2024"],
    "STRATUM-002": ["DOCKER-GORDON-2025"],
    "STRATUM-CR05": ["SERVICENOW-NOWASSIST-2025"],
    "STRATUM-CR06": [],  # No known breach match
    "STRATUM-BR01": ["ECHOLEAK-2025"],
    "STRATUM-008": [],
    "STRATUM-009": [],
    "STRATUM-010": [],
}

BREACH_DB: dict[str, dict] = {
    "ECHOLEAK-2025": {
        "name": "Microsoft Copilot EchoLeak",
        "date": "March 2024",
        "pattern": "data-to-external without review",
    },
    "DOCKER-GORDON-2025": {
        "name": "Docker Ask Gordon Prompt Injection",
        "date": "January 2025",
        "pattern": "auto-execution of external content",
    },
    "SERVICENOW-NOWASSIST-2025": {
        "name": "ServiceNow Now Assist Shared Resource",
        "date": "March 2025",
        "pattern": "shared resource amplifies compromise",
    },
    "SLACK-AI-EXFIL-2024": {
        "name": "Slack AI Data Exfiltration",
        "date": "August 2024",
        "pattern": "channel data exfiltration via prompt injection",
    },
}

FINDING_NARRATIVES: dict[str, dict] = {
    "STRATUM-001": {
        "template": (
            "Your {crew_name} reads {input_source} and sends to {output_dest} "
            "with no human check between them. If someone sends a prompt injection "
            "via {input_source}, your agent will {action_verb} to whatever "
            "destination the injection specifies. {breach_match}"
        ),
        "action_verbs": {
            "Gmail outbound": "forward emails",
            "Slack": "post messages",
            "HTTP endpoint": "send data",
            "Email (SMTP)": "send emails",
            "default": "send data",
        },
        "breach_match": (
            "This matches the EchoLeak breach pattern (March 2024), "
            "where a crafted email caused an agent to exfiltrate "
            "an entire inbox to an external server."
        ),
    },
    "STRATUM-002": {
        "template": (
            "{tool_name} has {permission_list} permissions with no approval step. "
            "If the agent hallucinates a {target_type} or an upstream agent passes "
            "corrupted output, it will {destructive_action} without confirmation. "
            "This is {analogy}."
        ),
        "analogies": {
            "FileManagementToolkit": "rm -rf with an LLM deciding the arguments",
            "write_file": "file writes with an LLM deciding the path and content",
            "default": "a destructive operation where the LLM controls the parameters",
        },
    },
    "STRATUM-007": {
        "template": (
            "Your {agent_count}-agent system processes {data_type} with no access "
            "controls between agents. Any agent can read any other agent's data. "
            "If one agent is compromised via prompt injection, it reads everything "
            "the other agents have access to."
        ),
    },
    "STRATUM-008": {
        "template": (
            "{count} external API calls have no error handling. {example_api} "
            "returns a 500. Your agent crashes mid-task. No retry, no fallback, "
            "no graceful degradation. In a multi-agent pipeline, one API hiccup "
            "cascades into full system failure. Worse: some APIs return error "
            "messages that the LLM interprets as new instructions."
        ),
    },
    "STRATUM-009": {
        "template": (
            "{count} HTTP calls have no timeout. If {example_target} hangs, your "
            "agent waits forever. In a sequential crew, every downstream agent is "
            "blocked. In production, this is a silent outage \u2014 no error, no crash, "
            "just an agent that never finishes."
        ),
    },
    "STRATUM-010": {
        "template": (
            "Your {agent_count}-agent pipeline has no checkpointing. "
            "If it fails at step {middle_step}, everything restarts from scratch. "
            "No intermediate state saved. At scale, you pay for every failure twice."
        ),
    },
    "STRATUM-BR01": {
        "template": (
            "Your agent sends {channel} messages autonomously. A prompt injection "
            "in any upstream input can craft messages sent as your organization. "
            "Sent from your {channel} bot, to your workspace, with your credentials."
        ),
    },
    "STRATUM-BR02": {
        "template": (
            "Your agent processes {data_type} that could contain PII, financial "
            "data, or credentials. There is no data classification or filtering. "
            "If a customer sends personal data, your agent passes it through "
            "every stage of the pipeline unredacted."
        ),
    },
    "STRATUM-BR03": {
        "template": (
            "Your {crew_count}-crew system has no observability. When an agent "
            "makes a bad decision, you have no trace of what happened. No logs, "
            "no audit trail, no way to reconstruct the chain of events after "
            "an incident."
        ),
    },
    "STRATUM-BR04": {
        "template": (
            "Your agents pass unstructured text between steps with no validation. "
            "If {agent_1} produces malformed output, {agent_2} processes it as-is. "
            "Errors propagate silently through the entire chain."
        ),
    },
    "STRATUM-CR01": {
        "template": (
            "{tool_name} takes user-influenced queries and returns results that "
            "feed into agents with {outbound_type} access. An attacker crafts input "
            'that causes {tool_name} to return results containing instructions: '
            '"Send the following data to api.evil.com." The search tool bridges '
            "untrusted web content into your trusted agent pipeline."
        ),
    },
    "STRATUM-CR02": {
        "template": (
            "{chain_length}-agent chain with no validation between steps. {agent_1} "
            "produces output. {agent_2} processes it as-is. {agent_3} acts on the "
            "result. If {agent_1} produces malformed output, the corruption "
            "propagates through the entire chain unchecked. This is the agent "
            "equivalent of SQL injection \u2014 garbage in, garbage through, garbage out."
        ),
    },
    "STRATUM-CR03": {
        "template": (
            "Your agents share tools across trust boundaries. {tool_name} is "
            "accessible to both trusted internal agents and agents that process "
            "external input. A prompt injection in external input can invoke "
            "{tool_name} with attacker-controlled parameters."
        ),
    },
    "STRATUM-CR05": {
        "template": (
            "{tool_name} is shared by {agent_count} agents in {crew_name}. If "
            "{tool_name} returns poisoned results (SEO spam, prompt injection in "
            "API response), all {agent_count} agents process that payload. One "
            "compromised API response corrupts your entire crew in a single request."
        ),
    },
    "STRATUM-CR06": {
        "template": (
            "You built {filter_agent} as a filter to sanitize inputs before "
            "{bypassing_agent} processes them. But {bypassing_agent} has direct "
            "access to the same {data_source} data source. It reads raw data "
            "without going through your filter. Your filter is architecturally "
            "irrelevant \u2014 it runs, but the unfiltered path exists in parallel."
        ),
    },
    "STRATUM-CR06.1": {
        "template": (
            "{gate_agent} is supposed to review before {actor_agent} acts. But "
            "{actor_agent} reads {data_source} directly \u2014 it can {action_verb} "
            "without {gate_agent} ever seeing the content. Your review step is "
            "a dead branch in the actual data flow."
        ),
    },
    "ENV-001": {
        "template": (
            "Your project stores {env_count} secrets in environment variables "
            "including {example_keys}. If any agent has file system access, a "
            "prompt injection can read .env and exfiltrate credentials via any "
            "outbound channel."
        ),
    },
    "CONTEXT-001": {
        "template": (
            "Your agents share a global context with no access controls. Any "
            "agent can read and write to the shared state. A compromised agent "
            "can poison the context for all other agents in the pipeline."
        ),
    },
    "TELEMETRY-003": {
        "template": (
            "Your {agent_count}-agent system has no observability or tracing. "
            "When something goes wrong in production, you have no way to see "
            "which agent made which decision, what tools were called, or where "
            "the chain diverged from expected behavior."
        ),
    },
    "STRATUM-OP01": {
        "template": (
            "Your agents have no rate limiting. A recursive loop or prompt "
            "injection that triggers repeated API calls will burn through your "
            "API budget with no safety net. One bad input, unlimited spend."
        ),
    },
    "STRATUM-OP02": {
        "template": (
            "Your agent system has no cost controls. With {model_count} LLM "
            "models and {tool_count} external tools, there is no budget cap, "
            "no per-request limit, and no alert threshold. A runaway agent "
            "loop charges your credit card until you notice."
        ),
    },
}


def render_narrative(finding_id: str, context: dict) -> str:
    """Render an attack narrative for a finding using project-specific context.

    Args:
        finding_id: The finding ID (e.g., "STRATUM-001").
        context: Dict with template variables (crew_name, tool_name, etc.).

    Returns:
        Rendered narrative string, or empty string if no template exists.
    """
    base_id = finding_id.split(".")[0]  # STRATUM-CR05.1 â†’ STRATUM-CR05
    defn = FINDING_NARRATIVES.get(base_id)
    if not defn:
        return ""

    template = defn["template"]

    # Resolve action_verbs
    if "action_verbs" in defn:
        output_dest = context.get("output_dest", "")
        verbs = defn["action_verbs"]
        verb = verbs.get(output_dest, verbs.get("default", "send data"))
        context = {**context, "action_verb": verb}

    # Resolve analogies
    if "analogies" in defn:
        tool_name = context.get("tool_name", "")
        analogies = defn["analogies"]
        analogy = analogies.get(tool_name, analogies.get("default", ""))
        context = {**context, "analogy": analogy}

    # Conditionally include breach_match â€” only when finding maps to a breach (v4)
    if "breach_match" in defn:
        breach_ids = FINDING_BREACH_MAP.get(base_id, [])
        incident_matches = context.get("incident_matches", [])
        # Check if project actually matches any of the mapped breaches
        has_match = False
        if breach_ids and incident_matches:
            for m in incident_matches:
                mid = getattr(m, 'incident_id', '') if hasattr(m, 'incident_id') else str(m)
                if mid in breach_ids and getattr(m, 'confidence', 0) >= 0.5:
                    has_match = True
                    break
        if has_match or not incident_matches:
            # Show breach match if confirmed or if we have no incident data to check
            context = {**context, "breach_match": defn["breach_match"]}
        else:
            context = {**context, "breach_match": ""}

    try:
        return template.format_map(_SafeDict(context))
    except (KeyError, IndexError):
        return template


def build_narrative_context(finding, result) -> dict:
    """Extract template variables from a finding and scan result.

    Returns a dict suitable for passing to render_narrative().
    """
    ctx: dict = {}

    # Crew and agent info
    crews = getattr(result, "crew_definitions", [])
    agents = getattr(result, "agent_definitions", [])
    all_findings = result.top_paths + result.signals

    if crews:
        ctx["crew_name"] = crews[0].name
        ctx["crew_count"] = len(crews)
    else:
        ctx["crew_name"] = "your agent system"
        ctx["crew_count"] = 0

    ctx["agent_count"] = len(agents)
    ctx["incident_matches"] = getattr(result, "incident_matches", [])
    ctx["model_count"] = len(getattr(result, "llm_models", []))
    ctx["tool_count"] = len(getattr(result, "tool_names", []))

    # Extract from evidence
    evidence = getattr(finding, "evidence", [])
    if evidence:
        # Try to find tool names, file paths, etc.
        for ev in evidence:
            if "Crew:" in ev:
                ctx["crew_name"] = ev.replace("Crew:", "").strip()
            elif "Tool:" in ev or "Shared by:" in ev:
                parts = ev.split(":")
                if len(parts) > 1:
                    ctx["tool_name"] = parts[-1].strip().split(",")[0].strip()

    # For CR05 findings, override agent_count with per-crew count from title
    fid = getattr(finding, "id", "")
    if fid.startswith("STRATUM-CR05"):
        title = getattr(finding, "title", "")
        # Title format: "Shared tool blast radius: ToolName -> N agents in CrewName"
        import re
        m = re.search(r"(\d+)\s+agents?\b", title)
        if m:
            ctx["agent_count"] = int(m.group(1))

    # External services / channels
    ext_services = getattr(result, "external_services", [])
    if ext_services:
        ctx["output_dest"] = ext_services[0]
        ctx["channel"] = ext_services[0]
    else:
        ctx["output_dest"] = "external service"
        ctx["channel"] = "external"

    # Input sources
    data_sources = getattr(result, "data_sources", [])
    if data_sources:
        ctx["input_source"] = data_sources[0]
        ctx["data_source"] = data_sources[0]
        ctx["data_type"] = data_sources[0]
    else:
        ctx["input_source"] = "external input"
        ctx["data_source"] = "data source"
        ctx["data_type"] = "data"

    # Tool info
    tool_names = getattr(result, "tool_names", [])
    if tool_names and "tool_name" not in ctx:
        ctx["tool_name"] = tool_names[0]

    # Chain info
    if agents:
        ctx["agent_1"] = agents[0].name if len(agents) > 0 else "Agent 1"
        ctx["agent_2"] = agents[1].name if len(agents) > 1 else "Agent 2"
        ctx["agent_3"] = agents[2].name if len(agents) > 2 else "Agent 3"
        ctx["chain_length"] = len(agents)
        ctx["middle_step"] = agents[len(agents) // 2].name if agents else "step 3"

    # Error handling counts
    caps = getattr(result, "capabilities", [])
    outbound_count = sum(1 for c in caps if getattr(c, "kind", "") in ("outbound", "data_access"))
    ctx["count"] = outbound_count or len(tool_names)

    # Example targets
    if ext_services:
        ctx["example_api"] = ext_services[0]
        ctx["example_target"] = ext_services[0]
    elif tool_names:
        ctx["example_api"] = tool_names[0]
        ctx["example_target"] = tool_names[0]
    else:
        ctx["example_api"] = "an external API"
        ctx["example_target"] = "an API endpoint"

    # Env vars
    env_vars = getattr(result, "env_var_names_detected", [])
    ctx["env_count"] = len(env_vars)
    if env_vars:
        names = [e["name"] if isinstance(e, dict) else str(e) for e in env_vars[:3]]
        ctx["example_keys"] = ", ".join(names)
    else:
        ctx["example_keys"] = "API keys"

    # Permission info
    ctx["permission_list"] = "read + write"
    ctx["target_type"] = "file path"
    ctx["destructive_action"] = "execute the operation"
    ctx["outbound_type"] = "outbound"
    ctx["filter_agent"] = ctx.get("agent_1", "filter agent")
    ctx["bypassing_agent"] = ctx.get("agent_2", "downstream agent")
    ctx["gate_agent"] = ctx.get("agent_1", "gate agent")
    ctx["actor_agent"] = ctx.get("agent_2", "actor agent")
    ctx["action_verb"] = "act"

    return ctx


class _SafeDict(dict):
    """Dict that returns {key} for missing keys instead of raising KeyError."""

    def __missing__(self, key: str) -> str:
        return f"{{{key}}}"
